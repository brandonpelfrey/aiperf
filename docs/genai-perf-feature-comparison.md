<!--
# SPDX-FileCopyrightText: Copyright (c) 2025-2026 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
-->
# GenAI-Perf vs AIPerf CLI Feature Comparison Matrix

This comparison matrix shows the supported CLI options between GenAI-Perf and AIPerf.

> [!NOTE]
> This is a living document and will be updated as new features are added to AIPerf.


**Legend:**
- âœ… **Fully Supported** - Feature available with same/similar functionality
- ğŸŸ¡ **Partial Support** - Feature available but with different parameters or limitations
- **`N/A`** **Not Applicable** - Feature not applicable
- âŒ **Not Supported** - Feature not currently supported

---

## **Core Subcommands**

| Subcommand | Description | GenAI-Perf | AIPerf | Notes |
|------------|-------------|------------|---------|-------|
| **analyze-trace** | Analyze mooncake trace for prefix statistics | âŒ | âœ… | |
| **profile** | Profile LLMs and GenAI models | âœ… | âœ… | |
| **plot** | Generate visualizations from profiling data | âŒ | âœ… | Auto-detects multi-run comparison vs single-run analysis; supports dashboard mode |
| **analyze** | Sweep through multiple scenarios | âœ… | âŒ | |
| **config** | Run using YAML configuration files | âœ… | âŒ | |
| **create-template** | Generate template configs | âœ… | âŒ | |
| **process-export-files** | Multi-node result aggregation | âœ… | **`N/A`** | AIPerf will aggregate results in real-time |

---

## **Endpoint Types Support Matrix**

`--endpoint-type`

| Endpoint Type | Description | GenAI-Perf | AIPerf | Notes |
|---------------|-------------|------------|---------|-------|
| **chat** | Standard chat completion API (OpenAI-compatible) | âœ… | âœ… | |
| **completions** | Text completion API for prompt completion | âœ… | âœ… | |
| **embeddings** | Text embedding generation for similarity/search | âœ… | âœ… | |
| **rankings** | Text ranking/re-ranking for search relevance | âœ… | âœ… | GenAI-Perf's generic `rankings` is HF TEI compatible; AIPerf has separate `nim_rankings`, `hf_tei_rankings` and `cohere_rankings` |
| **hf_tei_rankings** | HuggingFace TEI re-ranker API | âœ… | âœ… | GenAI-Perf uses generic `rankings` endpoint |
| **nim_rankings** | NVIDIA NIM re-ranker API | âŒ | âœ… | |
| **cohere_rankings** | Cohere re-ranker API | âŒ | âœ… | |
| **responses** | OpenAI responses endpoint | âŒ | âŒ | |
| **dynamic_grpc** | Dynamic gRPC service calls | âœ… | âŒ | |
| **huggingface_generate** | HuggingFace transformers generate API | âœ… | âœ… | `/generate` and `/generate_stream` supported |
| **image_generation** | OpenAI-compatible image generation (`/v1/images/generations`) | âŒ | âœ… | Text-to-image benchmarking with SGLang, supports raw export for image extraction |
| **image_retrieval** | Image search and retrieval endpoints | âœ… | âŒ | |
| **nvclip** | NVIDIA CLIP model endpoints | âœ… | âŒ | |
| **multimodal** | Multi-modal (text + image/audio) endpoints | âœ… | âœ… | AIPerf uses `chat` endpoint with multimodal content |
| **generate** | Generic text generation endpoints | âœ… | âŒ | |
| **kserve** | KServe model serving endpoints | âœ… | âŒ | |
| **template** | Template-based inference endpoints | ğŸŸ¡ | âœ… | AIPerf supports multimodal and multi-turn templates |
| **tensorrtllm_engine** | TensorRT-LLM engine direct access | âœ… | âŒ | |
| **vision** | Computer vision model endpoints | âœ… | âœ… | AIPerf uses `chat` endpoint for VLMs |
| **solido_rag** | SOLIDO RAG endpoint | âŒ | âœ… | |

---

## **Endpoint Configuration**

| Feature | CLI Option | GenAI-Perf | AIPerf | Notes |
|---------|------------|------------|---------|-------|
| **Model Names** | `-m` | âœ… | âœ… | |
| **Model Selection Strategy** | `--model-selection-strategy`<br>`{round_robin,random}` | âœ… | âœ… | |
| **Backend Selection** | `--backend`<br>`{tensorrtllm,vllm}` | âœ… | âŒ | |
| **Custom Endpoint** | `--endpoint` | âœ… | âœ… | |
| **Endpoint Type** | `--endpoint-type` | âœ… | âœ… | [See detailed comparison above](#endpoint-types-support-matrix) |
| **Server Metrics URL** | `--server-metrics-url` | âŒ | âœ… | AIPerf uses `--server-metrics` (enabled by default, auto-collects Prometheus metrics from endpoint). GenAI-Perf's `--server-metrics-url` is for GPU telemetry only. |
| **Streaming** | `--streaming` | âœ… | âœ… | |
| **URL** | `-u URL`<br>`--url` | âœ… | âœ… | |
| **Request Timeout** | `--request-timeout-seconds` | âŒ | âœ… | |
| **API Key** | `--api-key` | ğŸŸ¡ | âœ… | For GenAI-Perf, use `-H` instead |

---

## **Input Configuration**

| Feature | CLI Option | GenAI-Perf | AIPerf | Notes |
|---------|------------|------------|---------|-------|
| **Extra Inputs** | `--extra-inputs` | âœ… | âœ… | |
| **Custom Headers** | `--header -H` | âœ… | âœ… | |
| **Input File** | `--input-file` | âœ… | âœ… | |
| **Dataset Entries/Conversations** | `--num-dataset-entries` | âœ… | âœ… | |
| **Public Dataset** | `--public-dataset`<br>`{sharegpt}` | âŒ | âœ… | |
| **Custom Dataset Type** | `--custom-dataset-type`<br>`{single_turn,multi_turn,random_pool,mooncake_trace}` | âŒ | âœ… | GenAI-Perf infers dataset type from input file format |
| **Fixed Schedule** | `--fixed-schedule` | âœ… | âœ… | |
| **Fixed Schedule Auto Offset** | `--fixed-schedule-auto-offset` | âŒ | âœ… | |
| **Fixed Schedule Start/End Offset** | `--fixed-schedule-start-offset`<br>`--fixed-schedule-end-offset` | âŒ | âœ… | |
| **Random Seed** | `--random-seed` | âœ… | âœ… | |
| **GRPC Method** | `--grpc-method` | âœ… | âŒ | |

---

## **Output Configuration**

| Feature | CLI Option | GenAI-Perf | AIPerf | Notes |
|---------|------------|------------|---------|-------|
| **Artifact Directory** | `--artifact-dir` | âœ… | âœ… | |
| **Checkpoint Directory** | `--checkpoint-dir` | âœ… | âŒ | |
| **Generate Plots** | `--generate-plots` | âœ… | ğŸŸ¡ | AIPerf uses separate `aiperf plot` subcommand with more features |
| **Enable Checkpointing** | `--enable-checkpointing` | âœ… | âŒ | |
| **Profile Export File** | `--profile-export-file` | âœ… | âœ… | AIPerf works as a prefix for the profile export file names. |

---

## **Tokenizer Configuration**

| Feature | CLI Option | GenAI-Perf | AIPerf | Notes |
|---------|------------|------------|---------|-------|
| **Tokenizer** | `--tokenizer` | âœ… | âœ… | |
| **Tokenizer Revision** | `--tokenizer-revision` | âœ… | âœ… | |
| **Tokenizer Trust Remote Code** | `--tokenizer-trust-remote-code` | âœ… | âœ… | |

---

## **Load Generator Configuration**

| Feature | CLI Option | GenAI-Perf | AIPerf | Notes |
|---------|------------|------------|---------|-------|
| **Concurrency** | `--concurrency` | âœ… | âœ… | |
| **Request Rate** | `--request-rate` | âœ… | âœ… | |
| **Request Count** | `--request-count`<br>`--num-requests` | âœ… | âœ… | |
| **Request Rate w/ Max Concurrency** | `--request-rate` with `--concurrency` | âŒ | âœ… | Dual control of rate and concurrency ceiling |
| **Measurement Interval** | `--measurement-interval -p` | âœ… | **`N/A`** | Not applicable to AIPerf |
| **Stability Percentage** | `--stability-percentage -s` | âœ… | **`N/A`** | Not applicable to AIPerf |

---

## **Arrival Pattern Configuration**

| Feature | CLI Option | GenAI-Perf | AIPerf | Notes |
|---------|------------|------------|---------|-------|
| **Arrival Pattern** | `--arrival-pattern`<br>`{constant,poisson,gamma}` | âŒ | âœ… | Controls inter-arrival time distribution |
| **Arrival Smoothness** | `--arrival-smoothness`<br>`--vllm-burstiness` | âŒ | âœ… | Gamma distribution shape: <1=bursty, 1=Poisson, >1=smooth |

---

## **Duration-Based Benchmarking**

| Feature | CLI Option | GenAI-Perf | AIPerf | Notes |
|---------|------------|------------|---------|-------|
| **Benchmark Duration** | `--benchmark-duration` | âŒ | âœ… | Stop after N seconds |
| **Benchmark Grace Period** | `--benchmark-grace-period` | âŒ | âœ… | Wait for in-flight requests after duration (default: 30s, supports `inf`) |

---

## **Concurrency Control**

| Feature | CLI Option | GenAI-Perf | AIPerf | Notes |
|---------|------------|------------|---------|-------|
| **Session Concurrency** | `--concurrency` | âœ… | âœ… | Max concurrent sessions |
| **Prefill Concurrency** | `--prefill-concurrency` | âŒ | âœ… | Limit concurrent prefill operations (requires `--streaming`) |

---

## **Gradual Ramping**

| Feature | CLI Option | GenAI-Perf | AIPerf | Notes |
|---------|------------|------------|---------|-------|
| **Concurrency Ramp** | `--concurrency-ramp-duration` | âŒ | âœ… | Ramp concurrency from 1 to target over N seconds |
| **Prefill Concurrency Ramp** | `--prefill-concurrency-ramp-duration` | âŒ | âœ… | Ramp prefill concurrency over N seconds |
| **Request Rate Ramp** | `--request-rate-ramp-duration` | âŒ | âœ… | Ramp request rate over N seconds |

---

## **User-Centric Timing (KV Cache Benchmarking)**

| Feature | CLI Option | GenAI-Perf | AIPerf | Notes |
|---------|------------|------------|---------|-------|
| **User-Centric Rate** | `--user-centric-rate` | âŒ | âœ… | Per-user rate limiting with consistent turn gaps |
| **Number of Users** | `--num-users` | âŒ | âœ… | Number of simulated users (required with `--user-centric-rate`) |
| **Shared System Prompt** | `--shared-system-prompt-length` | âŒ | âœ… | System prompt shared across all users (KV cache prefix) |
| **User Context Prompt** | `--user-context-prompt-length` | âŒ | âœ… | Per-user unique context padding |

---

## **Warmup Phase Configuration**

| Feature | CLI Option | GenAI-Perf | AIPerf | Notes |
|---------|------------|------------|---------|-------|
| **Warmup Request Count** | `--warmup-request-count` | âœ… | âœ… | |
| **Warmup Duration** | `--warmup-duration` | âŒ | âœ… | Duration-based warmup stop condition |
| **Warmup Session Count** | `--num-warmup-sessions` | âŒ | âœ… | Session-based warmup stop condition |
| **Warmup Concurrency** | `--warmup-concurrency` | âŒ | âœ… | Override concurrency during warmup |
| **Warmup Prefill Concurrency** | `--warmup-prefill-concurrency` | âŒ | âœ… | Override prefill concurrency during warmup |
| **Warmup Request Rate** | `--warmup-request-rate` | âŒ | âœ… | Override request rate during warmup |
| **Warmup Arrival Pattern** | `--warmup-arrival-pattern` | âŒ | âœ… | Override arrival pattern during warmup |
| **Warmup Grace Period** | `--warmup-grace-period` | âŒ | âœ… | Grace period for warmup responses |
| **Warmup Concurrency Ramp** | `--warmup-concurrency-ramp-duration` | âŒ | âœ… | Ramp warmup concurrency |
| **Warmup Prefill Ramp** | `--warmup-prefill-concurrency-ramp-duration` | âŒ | âœ… | Ramp warmup prefill concurrency |
| **Warmup Rate Ramp** | `--warmup-request-rate-ramp-duration` | âŒ | âœ… | Ramp warmup request rate |

---

## **Session/Conversation Configuration (Multi-turn)**

| Feature | CLI Option | GenAI-Perf | AIPerf | Notes |
|---------|------------|------------|---------|-------|
| **Number of Sessions** | `--num-sessions` | âœ… | âœ… | |
| **Session Concurrency** | `--session-concurrency` | âœ… | âœ… | Use `--concurrency` for AIPerf |
| **Session Delay Ratio** | `--session-delay-ratio` | âœ… | âœ… | |
| **Session Turn Delay Mean** | `--session-turn-delay-mean` | âœ… | âœ… | |
| **Session Turn Delay Stddev** | `--session-turn-delay-stddev` | âœ… | âœ… | |
| **Session Turns Mean** | `--session-turns-mean` | âœ… | âœ… | |
| **Session Turns Stddev** | `--session-turns-stddev` | âœ… | âœ… | |

---

## **Input Sequence Length (ISL) Configuration**

| Feature | CLI Option | GenAI-Perf | AIPerf | Notes |
|---------|------------|------------|---------|-------|
| **Input Tokens Mean** | `--synthetic-input-tokens-mean`<br>`--isl` | âœ… | âœ… | |
| **Input Tokens Stddev** | `--synthetic-input-tokens-stddev` | âœ… | âœ… | |
| **Input Tokens Block Size** | `--prompt-input-tokens-block-size`<br>`--isl-block-size` | âŒ | âœ… | Used for `mooncake_trace` hash_id blocks |

---

## **Output Sequence Length (OSL) Configuration**

| Feature | CLI Option | GenAI-Perf | AIPerf | Notes |
|---------|------------|------------|---------|-------|
| **Output Tokens Mean** | `--output-tokens-mean`<br>`--osl` | âœ… | âœ… | |
| **Output Tokens Stddev** | `--output-tokens-stddev` | âœ… | âœ… | |
| **Output Tokens Mean Deterministic** | `--output-tokens-mean-deterministic` | âœ… | âŒ | Only applicable to Triton |

---

## **Batch Size Configuration**

| Feature | CLI Option | GenAI-Perf | AIPerf | Notes |
|---------|------------|------------|---------|-------|
| **Text Batch Size** | `--batch-size-text`<br>`--batch-size -b` | âœ… | âœ… | |
| **Audio Batch Size** | `--batch-size-audio` | âœ… | âœ… | |
| **Image Batch Size** | `--batch-size-image` | âœ… | âœ… | |

---

## **Prefix Prompt Configuration**

| Feature | CLI Option | GenAI-Perf | AIPerf | Notes |
|---------|------------|------------|---------|-------|
| **Number of Prefix Prompts** | `--num-prefix-prompts` | âœ… | âœ… | |
| **Prefix Prompt Length** | `--prefix-prompt-length` | âœ… | âœ… | |

---

## **Audio Input Configuration**

| Feature | CLI Option | GenAI-Perf | AIPerf | Notes |
|---------|------------|------------|---------|-------|
| **Audio Length Mean** | `--audio-length-mean` | âœ… | âœ… | |
| **Audio Length Stddev** | `--audio-length-stddev` | âœ… | âœ… | |
| **Audio Format** | `--audio-format`<br>`{wav,mp3,random}` | âœ… | âœ… | |
| **Audio Depths** | `--audio-depths` | âœ… | âœ… | |
| **Audio Sample Rates** | `--audio-sample-rates` | âœ… | âœ… | |
| **Audio Number of Channels** | `--audio-num-channels` | âœ… | âœ… | |

---

## **Image Input Configuration**

| Feature | CLI Option | GenAI-Perf | AIPerf | Notes |
|---------|------------|------------|---------|-------|
| **Image Width Mean** | `--image-width-mean` | âœ… | âœ… | |
| **Image Width Stddev** | `--image-width-stddev` | âœ… | âœ… | |
| **Image Height Mean** | `--image-height-mean` | âœ… | âœ… | |
| **Image Height Stddev** | `--image-height-stddev` | âœ… | âœ… | |
| **Image Format** | `--image-format`<br>`{png,jpeg,random}` | âœ… | âœ… | |

---

## **Service Configuration**

| Feature | CLI Option | GenAI-Perf | AIPerf | Notes |
|---------|------------|------------|---------|-------|
| **Record Processor Service Count** | `--record-processor-service-count`<br>`--record-processors` | âŒ | âœ… | |
| **Maximum Workers** | `--workers-max`<br>`--max-workers` | âŒ | âœ… | |
| **ZMQ Host** | `--zmq-host` | âŒ | âœ… | |
| **ZMQ IPC Path** | `--zmq-ipc-path` | âŒ | âœ… | |

---

## **Request Cancellation**

| Feature | CLI Option | GenAI-Perf | AIPerf | Notes |
|---------|------------|------------|---------|-------|
| **Request Cancellation Rate** | `--request-cancellation-rate` | âŒ | âœ… | Percentage of requests to cancel (0-100) |
| **Request Cancellation Delay** | `--request-cancellation-delay` | âŒ | âœ… | Seconds to wait before cancelling |

---

## **Additional Features**

| Feature | CLI Option | GenAI-Perf | AIPerf | Notes |
|---------|------------|------------|---------|-------|
| **Goodput Constraints** | `--goodput -g` | âœ… | âœ… | |
| **Verbose** | `-v --verbose` | âœ… | âœ… | |
| **Extra Verbose** | `-vv` | âœ… | âœ… | |
| **Log Level** | `--log-level` | âŒ | âœ… | `{trace,debug,info,notice,warning,success,error,critical}` |
| **UI Type** | `--ui-type --ui`<br>`{dashboard,simple,none}` | âŒ | âœ… | |
| **Help** | `-h --help` | âœ… | âœ… | |

---

## **Perf-Analyzer Passthrough Arguments**

> [!NOTE]
> GenAI-Perf supports passing through arguments to the Perf-Analyzer CLI. AIPerf does not support this, as it does not use Perf-Analyzer under the hood.

| Feature | CLI Option | GenAI-Perf | AIPerf | Notes |
|---------|------------|------------|---------|-------|
| **Perf-Analyzer Passthrough Arguments** | `--` | âœ… | **`N/A`** | Only applicable to GenAI-Perf |


---

## **Data Exporters**

| Feature | GenAI-Perf | AIPerf | Notes |
|---------|------------|--------|-------|
| Console output | âœ… | âœ… | |
| JSON output | âœ… | âœ… | [See discrepancies below](#json-output) |
| CSV output | âœ… | âœ… | |
| API Error Summary | âŒ | âœ… | |
| `profile_export.json` | âœ… | âœ… | Use `--export-level raw` in AIPerf to get raw input/output payloads |
| Per-Record Metrics | âŒ | âœ… | |
| `inputs.json` | âœ… | âœ… | AIPerf format is slightly different |

### Discrepancies

#### JSON Output

- Fields in the `input_config` section may differ between GenAI-Perf and AIPerf.

---

## **Advanced Features Comparison**

| Feature | GenAI-Perf | AIPerf | Notes |
|---------|------------|--------|-------|
| **Multi-modal support** | âœ… | âœ… | |
| **GPU Telemetry** | âœ… | âœ… | |
| **Streaming API support** | âœ… | âœ… | |
| **Multi-turn conversations** | âœ… | âœ… | Full multi-turn benchmarking with session tracking |
| **Payload scheduling** | âœ… | âœ… | Fixed schedule workloads |
| **Distributed testing** | âœ… | ğŸŸ¡ | Multi-node result aggregation |
| **Custom endpoints** | âœ… | âœ… |  |
| **Synthetic data generation** | âœ… | âœ… | |
| **Bring Your Own Data (BYOD)** | âœ… | âœ… | Custom dataset support |
| **Audio metrics** | âœ… | âŒ | Audio-specific performance metrics |
| **Vision metrics** | âœ… | âœ… | Image-specific performance metrics |
| **Image generation benchmarking** | âŒ | âœ… | Text-to-image with raw export for image extraction |
| **Live Metrics** | âŒ | âœ… | Live metrics display |
| **Dashboard UI** | âŒ | âœ… | Dashboard UI |
| **Reasoning token parsing** | âŒ | âœ… | Parsing of reasoning tokens |
| **Arrival pattern control** | âŒ | âœ… | Constant, Poisson, Gamma distributions with tunable burstiness |
| **Prefill concurrency limiting** | âŒ | âœ… | Fine-grained prefill queueing control for TTFT behavior |
| **Gradual ramping** | âŒ | âœ… | Smooth ramp-up for concurrency and rate |
| **Duration-based benchmarking** | âŒ | âœ… | Time-based stop conditions with grace periods |
| **User-centric timing** | âŒ | âœ… | Per-user rate limiting for KV cache benchmarking |
| **Configurable warmup phase** | ğŸŸ¡ | âœ… | AIPerf supports full warmup configuration (rate, concurrency, duration, ramping) |
| **HTTP trace metrics** | âŒ | âœ… | Detailed HTTP lifecycle timing (DNS, TCP, TLS, TTFB) |
| **Request cancellation** | âŒ | âœ… | Test timeout behavior and service resilience |
| **Timeslice metrics** | âŒ | âœ… | Per-timeslice metric breakdown |
| **Interactive plot dashboard** | âŒ | âœ… | Web-based exploration with dynamic metric selection and filtering |
| **Multi-run comparison plots** | âŒ | âœ… | Auto-detected Pareto curves and throughput analysis |

---
